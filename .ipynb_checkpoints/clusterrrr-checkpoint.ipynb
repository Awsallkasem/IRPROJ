{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.441769Z",
     "start_time": "2024-06-03T15:10:12.429545Z"
    }
   },
   "source": [
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from processquery import process\n"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.479266Z",
     "start_time": "2024-06-03T15:10:12.455782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of defining the retrieve_similar_documents function\n",
    "def retrieve_similar_documents(query_id, query, qrels, similarity_scores, tfidf_matrix, docs, vectorizer):\n",
    "    sorted_indices = np.argsort(similarity_scores.reshape(1, -1), axis=1)[0, ::-1]\n",
    "    threshold = 0\n",
    "    num_relevant = 0\n",
    "    returned_docs = []\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        doc_id = list(docs.keys())[idx]\n",
    "        if doc_id in qrels[query_id]:\n",
    "            num_relevant += 1\n",
    "        precision = num_relevant / (i + 1)\n",
    "        returned_docs.append(doc_id)\n",
    "        if precision >= threshold and i + 1 >= 5:\n",
    "            break\n",
    "\n",
    "    num_returned = i + 1\n",
    "    relevant_documents = [doc_id for doc_id in returned_docs if doc_id in qrels[query_id]]\n",
    "    Total = len(qrels[query_id])\n",
    "\n",
    "    return num_relevant, num_returned, precision, Total, relevant_documents\n",
    "\n",
    "# Modified read_docs_from_folder function\n",
    "def read_docs_from_folder(folder_path):\n",
    "    docs = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "                    doc_text = file.read()\n",
    "                doc_id = os.path.splitext(file_name)[0]  # Use the file name without extension as the document ID\n",
    "                docs[doc_id] = doc_text\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(f\"Error reading {file_name}: {e}\")\n",
    "    return docs\n"
   ],
   "id": "6cbba754db88fa48",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.521928Z",
     "start_time": "2024-06-03T15:10:12.514274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_tfidf_matrix(docs):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(docs.values())\n",
    "    return tfidf_matrix, vectorizer"
   ],
   "id": "e94d2b3a076332cd",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.556062Z",
     "start_time": "2024-06-03T15:10:12.537941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_qrels(qrels_file_paths):\n",
    "    qrels = {}\n",
    "    for qrels_file_path in qrels_file_paths:\n",
    "        with open(qrels_file_path, 'r') as qrels_file:\n",
    "            for line in qrels_file:\n",
    "                line_parts = line.strip().split(' ')\n",
    "                if len(line_parts) != 4:\n",
    "                    print(\"Invalid line format:\", line)\n",
    "                    continue\n",
    "\n",
    "                query_id, _, doc_id, relevance = line_parts\n",
    "                query_id = int(query_id)\n",
    "                doc_idd = doc_id.split('_')[0]  # Extract the document ID without the suffix\n",
    "\n",
    "                if query_id in qrels:\n",
    "                    qrels[query_id][doc_idd] = relevance\n",
    "                else:\n",
    "                    qrels[query_id] = {doc_idd: relevance}\n",
    "\n",
    "    return qrels\n",
    "\n",
    "\n",
    "def read_queries(queries_file_path):\n",
    "    queries = {}\n",
    "    with open(queries_file_path, 'r') as queries_file:\n",
    "        for line in queries_file:\n",
    "            line_parts = line.strip().split(None, 1)\n",
    "            if len(line_parts) < 2:\n",
    "                continue  # Skip lines that don't have the expected format\n",
    "            query_id = int(line_parts[0])\n",
    "            query = line_parts[1]\n",
    "            query = process(query)\n",
    "            queries[query_id] = query\n",
    "\n",
    "    return queries"
   ],
   "id": "2ceda4b17cc988d6",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.570580Z",
     "start_time": "2024-06-03T15:10:12.560074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_relevant_num(relevant_num_file_path, query_id, query, num_relevant, num_returned, precision, Total, relevant_documents, reciprocal_ranks):\n",
    "    with open(relevant_num_file_path, 'a+') as relevant_num_file:\n",
    "        relevant_num_file.write(f\"Query ID: {query_id}\\n\")\n",
    "        relevant_num_file.write(f\"Query: {query}\\n\")\n",
    "        relevant_num_file.write(f\"Relevant Documents: {num_relevant}\\n\")\n",
    "        relevant_num_file.write(f\"Total Returned Documents: {num_returned}\\n\")\n",
    "        relevant_num_file.write(f\"Precision: {precision}\\n\")\n",
    "        relevant_num_file.write(f\"Total: {Total}\\n\")\n",
    "        relevant_num_file.write(\"\\n\".join(relevant_documents))\n",
    "        relevant_num_file.write(\"\\n\\n\")\n",
    "\n",
    "    return reciprocal_ranks"
   ],
   "id": "454119f29e748cd5",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.591210Z",
     "start_time": "2024-06-03T15:10:12.584594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create relevant_num_file to store the results\n",
    "relevant_num_file_path = r\"C:\\Users\\user\\Documents\\IRSystem1\\cluster_relevant_num_queries.txt\""
   ],
   "id": "738664324ff4473b",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T15:10:12.639869Z",
     "start_time": "2024-06-03T15:10:12.612221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read relevance judgments (qrels)\n",
    "qrels_file_paths = glob.glob(r\"C:\\Users\\user\\Documents\\IRSystem1\\qrel1.txt\")\n",
    "qrels = read_qrels(qrels_file_paths)\n"
   ],
   "id": "d947591e5fd1ff4b",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-03T15:10:12.642879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read queries from file\n",
    "queries_file_path = r\"C:\\Users\\user\\Documents\\IRSystem1\\queries1.txt\"\n",
    "queries = read_queries(queries_file_path)"
   ],
   "id": "24bc82c3d4a09cbe",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load documents\n",
    "with open(r'C:\\Users\\user\\Documents\\IRSystem1\\docs12.pkl', 'rb') as file:\n",
    "    docs = pickle.load(file)"
   ],
   "id": "b1574bf0a4072003",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# تحويل المستندات إلى صورة مرجعية باستخدام TfidfVectorizer\n",
    "# tfidf_matrix, vectorizer = calculate_tfidf_matrix(docs)\n",
    "with open(r'C:\\Users\\user\\Documents\\IRSystem1\\tfidf_matrix_new.pkl', 'rb') as file:\n",
    "tfidf_matrix, vectorizer = pickle.load(file)"
   ],
   "id": "7ccef56df31dd1f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of clusters\n",
    "num_clusters = 4\n",
    "\n",
    "# Create the KMeans model with an explicit n_init parameter\n",
    "kmeans = KMeans(n_clusters=num_clusters, n_init=10)\n",
    "kmeans.fit(tfidf_matrix)\n"
   ],
   "id": "7fba09b93ff81b85",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "for query_id, query in queries.items():\n",
    "    print(\"Query ID:\", query_id)\n",
    "    print(\"Query:\", query)\n",
    "\n",
    "    if query_id not in qrels:\n",
    "        print('*********************************************')\n",
    "        print(\"No relevance judgments found for this query.\")\n",
    "        continue\n",
    "\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate similarity between query and each cluster\n",
    "    for i, cluster_center in enumerate(kmeans.cluster_centers_):\n",
    "        # Calculate similarity between query and cluster center using cosine_similarity\n",
    "        similarity_score = cosine_similarity(query_vector.reshape(1, -1), cluster_center.reshape(1, -1))[0, 0]\n",
    "        # Get documents matrix in the cluster\n",
    "        cluster_docs = tfidf_matrix[kmeans.labels_ == i]\n",
    "        # Print cluster ID and similarity score\n",
    "        print(\"Cluster ID: {}\".format(i))\n",
    "        print(\"Similarity Score between Query and Cluster_center-{}: {}\".format(i, similarity_score))\n",
    "        # Get indices of rows that match the condition kmeans.labels_ == i\n",
    "        doc_indices = np.where(kmeans.labels_ == i)[0]\n",
    "        # Get document IDs associated with the cluster\n",
    "        doc_ids = [list(docs.keys())[j] for j in doc_indices]\n",
    "        # Print document content and similarity scores for each document in the cluster\n",
    "        for j, (doc_id, doc_content) in enumerate(docs.items()):\n",
    "            if doc_id in doc_ids:\n",
    "                # Calculate similarity between document and cluster center using cosine_similarity\n",
    "                doc_similarity_score = cosine_similarity(tfidf_matrix[j], query_vector.reshape(1, -1))[0, 0]\n",
    "                # Print document ID, similarity score, and document content\n",
    "                print(\"Document ID in Cluster-{}, Document-{}: {}\".format(i, j, doc_id))\n",
    "                print(\"Similarity Score between Document-{} in Cluster-{} and the query: {}\".format(j, i, doc_similarity_score))\n",
    "                print(\"Document Content in Cluster-{}, Document-{}: {}\".format(i, j, doc_content))\n",
    "                print(\"\\n\")\n",
    "\n",
    "                # Retrieve similar documents\n",
    "                num_relevant, num_returned, precision, Total, relevant_documents = retrieve_similar_documents(query_id, query, qrels, doc_similarity_score, cluster_docs, docs, vectorizer)\n",
    "\n",
    "    # Save the results\n",
    "    save_relevant_num(relevant_num_file_path, query_id, query, num_relevant, num_returned, precision, Total, relevant_documents)\n"
   ],
   "id": "621cb5f948e20ae0",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
